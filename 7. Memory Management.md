## Chapter 7: Memory Management

- __Bare Machine__ - A system in where the designer is to decide how the memory should be addressed. This kind of system is used for dedicated system such as a computer controlling a plant. 

- The typical computer utilizes a __Resident Monitor__, where part of the memory is used by the operating system. In such system, one part of the memory is used by the __operating system__ and the remaining part of the memory is used to load user programs (__User Area__). 

- A user program is not permitted to touch the memory that is used by the Operating System. This is achieved by having a __Fence Address__. The fence address acts a fence or a marker that cannot be surpassed by the user program.

- There are two ways to keep checking if a user program is not surpassing the Fence Address: Software Check or Hardware check. Software check is slow. A hardware solution checks in parallel whether the address generated by the CPU has jumped the Fence Address. If yes, then set a trap, if no then allows for the CPU to use the memory. 

- The problem with the hardware solution is that it is fixed. Meaning that the hardware might not be compatible with an operating system that requires more or less allocated memory. A solution is to use a __Fence Register__ which is reloaded if the operating system is upgraded. 

- Memory can be divided into different areas besides just the o/s and user area. One of the areas called __buffer1__ can be used to swap out jobs (terminate jobs and put them back to secondary storage). The other area called __buffer 2__ can be used to swap in job from a secondary storage into main memory. The other areas (o/s and user) work separately. The user area is now able to take a process that has completed its CPU burst and move it into _buffer 1_. 


- To divide and protect the different memory areas a fence address is also used. A job in buffer 2 does not have to be transferred to user area. The fence address can be shifted up and encompass the area where the job is located (buffer 2) so that the user area can now execute that job. More memory partitions allow for better memory management. 

- __Multiprogramming with Fixed number of Tasks__ - here main memory will partitioned into many fixed segments or areas, including the o/s area. An instruction pointer can be used to make different areas of the memory become active. In this case, a segment must be protected using two registers: A __lower bound register__ and an __upper bound register__. 

- If the CPU process is trying to access an area below the lower bound address and above the upper bound address, then that process is not allocated memory. 

- A __base register__ and a __limit register__ can be used to check if the CPU generated address is requesting to access a part of the memory that is not allowed for that process. If the CPU logical address is less than the limit register, then that logical address is added to the Base address and given access to the physical address in memory. If the logical address is more that the limit address, then is send to a trap. 

- The way the operating system decides where a job is loaded into main memory is based on the fixed size of the partition in memory. 

- __First Fit Algorithm__ - A partition is allocated fully to a job or not based on an algorithm that checks and allocated which is the first segment of the memory that is more than or equal to the size required by the process. Because it is fixed, a partition cannot be allocated to other jobs when a job has been loaded into it. There could be a case where the memory partition allocated to a process is bigger in size than what the process requires. The remaining allocated memory is wasted and also referred to as an __internal fragmentation__.


- __Best Fit Algorithm__ - allocates the memory partition that leads to the minimum internal fragmentation. This means that it has to check _all segments_ in memory to choose the best one for the size required by the process. The complexity of this algorithm is a lot higher than the previous algorithm. 

- There could be a case when the partitions in memory are all smaller in size than what is required by a process. In such scenario, there is a case of __external fragmentation__ because there are free memory partition of which not can be used. 

- A __memory module__ keep track on information about the main memory partition sizes and statuses. 

- The status (Free / Allocated) of each memory partition is kept in what is called a __Partition Allocation Table__.

- Another type of memory management is called __Multiprogramming with Variable number of Tasks__ (MVT). In such case, we don't have a fixed number of partitions. In fact, in MVT, the number and size of partition vary depending on the size requirement from different jobs.  

- In the MVT, initially (no jobs) there will be two partitions in memory: O/S area and User area.

- Assuming we have the following jobs:

```Pascal
// memory size 256K
// initial memory allocation
O/S Partition = 40K
User Partition = 216K

// memory requirements for jobs using a FCFS scheduling
J1 = 60K , 10 time units (CPU burst time)
J2 = 100K, 5 time units
J3 = 30K, 20 time units
J4 = 70K, 8 time units
J5 = 50K, 15 time units
J6 = 60K, 9 time units

// Allocation happens the following way

// J1 allocation
2 Partition: 40K --> 100K
Unallocated Partition : 156K

// J2 Allocation
Partition: 100K --> 200K
Unallocated Partition: 56K

// J3 Allocation
Partition: 200K --> 230K
Unallocated Partition: 26K
```

- No other jobs can be loaded into memory since all of them exceed the size of the remaining partition. The remaining unallocated partition become an external fragmentation. 

- After 5 time units, J2 will complete execution and the partition held by J2 will change its state to unallocated.

```Pascal
O/S Partition: 0 --> 40K

// J1 allocation
2 Partition: 40K --> 100K
Unallocated partition: 100K --> 200K (after J2 released it)

// J3 Allocation
Partition: 200K --> 230K
Unallocated Partition: 26K (230K - 256K)

// J4 Allocation
Partition: 100K --> 170K
Unallocated Partition: 30K (170K - 200K) // this makes two unallocated partitions in memory
```

- After 5 more time units, J1 will complete execution

```Pascal
O/S Partition: 0 --> 40K

Unallocated partition: 60K (40K - 100K) (after J1 released it)

// J4 Allocation
Partition: 100K --> 170K
Unallocated Partition: 30K (170K - 200K) 

// J3 Allocation
Partition: 200K --> 230K
Unallocated Partition: 26K (230K - 256K)

// J5 Allocation
Partition: 40K --> 90K
Unallocated Partition: 10K (90K - 100K)
```

- In the above given scenario, there is a total of 66K of memory which is unallocated. The remaining job only requires 60K. In order to use the remaining memory, all the free unallocated partition can be compacted together contiguously to make a bigger partition (size: 66K). Such technique is called __Memory Compaction__. After memory compaction jobs _J5_, _J4_, _J3_ and _J6_ will occupy a total of 250K memory with a remaining unallocated partition of size 6K.

- In the MVT, two tables are kept: A partition allocation table and a __free area table__ (containing the free unallocated spaces). Free area table contains the size of the area and the starting address of the partition.

- In MVT, you can allow internal fragmentation by merging a very small free area to an already allocated partition. This may avoid some cost.

- Memory compaction is a very costly solution. To come up with a better solution the __Paged Memory Management__ technique was introduced.

- In paged memory management, every process is divided into a number of pages. Processes are divided into a __number of pages__. Memory is divided into a __number of frames__. The page size is the same size as the frame size.

- Any page can be loaded into any of the frames. But there has to be some mapping stating in which frames in memory those pages were loaded. From a frame number it is possible to find out the physical address on the frame in memory where the job pages were allocated. 

- Every pages a _P_ number of bytes (Page size) with a logical address _L_. A logical address has two components: a page number _p_ and an offset/displacement _d_ within that page. This information is stored in a __Page Map Table (PMT)__ Those components are calculated as follows:

```Pascal
// logical address calculation
p = L div P // integer division
d = L mod P

// physical address calculation
Physical address = (f-1) * P + d
```

- Using the paging technique is beneficial because a job's pages can be loaded into memory frames without those frames having to be contiguous as in the previous technique (MFT) or (MVT). This also avoids the problem and complexity of compaction.

- In PMM, there will be internal fragmentation if the page size if (p = L div P) have a remainder. The maximum number of internal fragmentation is equal to (P - 1).

- If a user is trying to access an inaccessible memory frame through a program, the PMT keeps a bit (0/1) that checks if that program page corresponds to that particular requested frame. If the page contains a 0 bit that means there is no corresponding page for that frame.

- In PMM, the __modular structure__ of the program is broken. 

- Instead of having pages, a job is broken down in segments that contain specific modules of the program. Such technique is called __Segmented Memory Management__. 

### Segmented Memory Management (SMM)

- Given the following program with the specific functions of modules:

```Pascal
// functions of different size
Main()
Sqrt()
Factorial()
Billing()
```

- In SMM, the program is broken down to segments, where each segment contain one of the functions or module of that program.

- Each segment is then loaded into memory just as the MVT technique -- with a Base address and Limit address. First, the CPU generates a logical address (s, d) for each segment to be loaded into memory. A __segment memory table__ is needed to map the logical address to the physical address in memory. The offset of the segment cannot exceed the limit address of that segment in memory.

- The first check is comparing if the offset of the segment _d_ is less than limit. If yes, the base is added to the _d_ to set the physical address in main memory. 

- The order of the segments can be implements based on the same order the modules or functions were coded in the program. 

- SMM and PMM can be combined to achieve a new technique called the __Paged Segmented Memory Management__ (PSMM).

- In PSMM, the CPU generates a _(s, d)_ logical address pair for a program. Then _s_ is used to calculate the _limit_ and _PMT Base_ and stored in a __segment table__. Given that _s_ is divided into a number of pages, if _d_ is less that _limit_ then _d_ is broken into two components _(p, d')_. Then add page number _p_ with the _PMT Base_ to give a particular entry within the PMT table of _s_. The entries in _PMT_ contain the frame number _f_ . Lastly, _f_ and _d'_ are used to give the physical address in main memory. 

### Demand Paging (Virtual Memory Management) - Another memory management technique.

- VMM is a paging technique so there will be equal size of frames or segments allocated in main memory to load the program on. 

- In VMM, there is no need to have all the pages loaded into memory at the same time. The instructions of a program can wait for other to execute and the be loaded into main memory when needed. This means that in order for a job to start execution there is no need to load the entire logical space pages of that job into main memory. 

- The following is a flowchart of the way VMM works:

```Pascal
Step 1: Start Processing an Instruction
Step 2: CPU Generate Address
Step 3: Page number is generated
Step 4: Check PMT if Page available in Main Memory

If page in MM:
  Step 5: Fetch the data & compute the instruction
  Step 6: CPU advances to the next instruction
  Step 7: Process continues
Else:
  Step 5: Page fault interrupt is processed 
```

- Process of page fault interrupt:

```Pascal
// Step 5:
Step 1: 
If there is no free block in MM:
  Step 2: Select a page in MM for replacement
  Step 3: Adjust PMT (change bit)
  Step 4: Check if page was modified
  If yes:
    Step 5: Write back into Secondary Storage
  Else:
    Step 6: Free address for the new page
Else:
  Step 2: Get Disk Access of the new page from FMT (File Map Table)
  Step 3: Read in Page
  Step 4: Adjust PMT for new page
  Step 5: Restart the interrupted instruction
  Step 6: Continue processing instructions
```

- There are many page replacement techniques. The simplest technique is called __FIFO (First in First out)__ replacement. The page that was loaded first in memory is the page that is terminated or replaced by the new one. 
 
- Another techniques is called the Optimal replacement technique, where the page being replaced is not needed anytime near in the future. In the case of the FIFO technique, the page being replace might be the page to used next and thus incur a cost (including I/O operation and more page interrupts). __Least Recently Used (LRU)__ replacement techniques is an approximation of the OPTIMAL replacement technique.

- Given a list of page numbers referred to by a user program:

```Pascal
// order of page numbers
7, 0, 1 ,2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1 ,7, 0, 1, 

// three memory frames are available 
[ ]
[ ]
[ ]
```

- FIFO functions as follows:

```Pascal
// page 7 issues a page interrupt and then is loaded into MM
// no page replacement in needed since there is free frame
[7]
[ ]
[ ]

// page 0 is referred, page interrupt, no page replacement
[7]
[0]
[ ]

// page 1 referred, page interrupt, no page replacement
[7]
[0]
[1]

// page 2 referred, page interrupt, yes page replacement using FIFO
[2]
[0]
[1]

// page 0 nothing happens

// page 3 referred, page interrupt, yes page replacement
[2]
[3]
[1]

// page 0
[2]
[3]
[0]

// page 4
[4]
[3]
[0]

// page 2
[4]
[2]
[0]

// page 3
[4]
[2]
[3]

// page 0
[0]
[2]
[3]

// page 3, 2 - nothing happens

// page 1
[0]
[1]
[3]

// page 2
[0]
[1]
[2]

// page 0, 1 

// page 7
[7]
[1]
[2]

// page 0
[7]
[0]
[2]

// page 1
[7]
[0]
[1]
```

- With the above process, two ratios can be calculated: __hit ratio__s and __miss ratio__. 
 
- Hit ratio is the number of hits divided by the number of access (5/20). Miss ratio is (15/20). 

- OPTIMAL function as follows:
```Pascal
// page 7
[7]
[ ]
[ ]

// page 0
[7]
[0]
[ ]

// page 1
[7]
[0]
[1]

// page 2 (replace number of 7 since it needed late on in future)
[2]
[0]
[1]

// page 0 
// page 3 (replace 1)
[2]
[0]
[3]

// page 4
[2]
[4]
[3]

// page 2
// page 3

// page 0
[2]
[0]
[3]
// page 3
// page 2
// page 1
[2]
[0]
[1]

// page 2
// page 0
// page 1
// page 7
[7]
[0]
[1]

// page 0
// page 1
```

- miss ratio (9/20); hit ratio (11/20).